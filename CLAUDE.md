# Sequential Ecosystem - Complete Architecture & xstate Integration

---

## Project Overview

**sequential-ecosystem** is a monorepo for building **infinite-length task execution systems** with automatic suspend/resume on HTTP calls. It uses xstate for state management in two distinct patterns:

1. **Implicit xstate (FetchFlow)**: Automatic pausing on every HTTP call via sequential-fetch VM
2. **Explicit xstate (FlowState)**: Graph-based task flows with alternative execution paths

All code is deployment-agnostic and works across Node.js, Deno, and Bun without changes.

---

## Directory Structure

```
sequential-ecosystem/
├── CLAUDE.md                          # This file - complete reference
├── CHANGELOG.md                       # Version history
├── TODO.md                            # Outstanding tasks
├── package.json                       # Root monorepo config + CLI entry
├── cli.js                             # NPX entry point (compiled from cli.ts)
├── cli.ts                             # CLI implementation
├── tools/                             # Shared CLI utilities
│   ├── create-task.ts                 # Task scaffolding tool
│   ├── sync-tasks.ts                  # DB sync utility
│   └── ...more tools
├── tasks/                             # Default task storage (folder-based)
│   ├── task-1/
│   │   ├── code.js                    # Task code
│   │   ├── config.json                # Task metadata
│   │   └── results.json               # Execution results
│   └── task-N/
├── packages/                          # Core libraries
│   ├── sequential-fetch/              # VM with implicit xstate (FetchFlow)
│   ├── sequential-flow/               # VM with explicit xstate support (FlowState)
│   ├── tasker-sequential/             # Task execution engine
│   ├── tasker-adaptor/                # Storage adaptor interface
│   ├── tasker-adaptor-sqlite/         # SQLite storage implementation
│   ├── tasker-adaptor-supabase/       # PostgreSQL storage (Supabase)
│   ├── sdk-http-wrapper/              # HTTP client SDK
│   └── tasker-wrapped-services/       # Pre-wrapped service libraries
└── dist/                              # Compiled CLI (generated on build)
```

---

## Two xstate Integration Patterns

### Pattern 1: Implicit xstate (FetchFlow) - Default

**sequential-fetch** implements automatic state management via the **FetchFlow** pattern:

- **What it does**: Pauses JavaScript execution on EVERY HTTP call
- **How it works**: VM intercepts `fetch()` → suspends → stores state → waits for response
- **When to use**: Always - this is the default for all task execution
- **Developer responsibility**: Just write normal code with `fetch()` calls

**Example - Implicit xstate in action:**

```javascript
// tasks/gmail-search/code.js
async function searchGmail(userId) {
  // State 1: Initial state
  console.log('Fetching emails...');

  // State machine auto-pauses here (xstate implicit)
  const response = await fetch(`https://gmail.googleapis.com/gmail/v1/users/${userId}/messages`, {
    headers: {'Authorization': `Bearer ${token}`}
  });

  // State 2: Resumed after HTTP response
  const emails = await response.json();

  // Another implicit pause point
  const threads = await fetch('...').then(r => r.json());

  // State 3: Final state - all HTTP calls complete
  return {success: true, count: emails.length};
}
```

**How it executes:**

1. **Execution starts**: Task code runs in sequential-fetch VM
2. **First HTTP**: `fetch()` triggers suspension point
3. **State saved**: VM stores execution state (variables, line number)
4. **Control returns**: Parent can handle HTTP response
5. **Resume**: When response arrives, VM resumes from exact position
6. **Repeat**: Each `fetch()` is another xstate transition point
7. **Complete**: Task finishes when all HTTP calls done

**No explicit state setup required** - xstate transitions happen automatically.

### Pattern 2: Explicit xstate (FlowState) - Optional

**sequential-flow** supports **explicit state graphs** for complex workflows:

- **What it does**: Define task flows as explicit state machines with multiple execution branches
- **How it works**: Developer builds state graph → executor follows paths → one chunk per state
- **When to use**: Complex workflows with conditional branches, retries, or parallel execution
- **Developer responsibility**: Define states, transitions, and handlers

**Example - Explicit xstate state graph:**

```javascript
// tasks/complex-workflow/graph.js
const workflowGraph = {
  id: 'complexWorkflow',
  initial: 'fetchUsers',
  states: {
    fetchUsers: {
      onDone: 'processEmails',
      onError: 'handleError'
    },
    processEmails: {
      onDone: 'generateReport',
      onError: 'handleError'
    },
    generateReport: {
      onDone: 'complete',
      type: 'final'
    },
    handleError: {
      type: 'final'
    },
    complete: {
      type: 'final'
    }
  }
};

// tasks/complex-workflow/code.js
async function complexWorkflow(input) {
  // Each state executes ONE chunk of code
  // xstate manages which state runs next

  if (currentState === 'fetchUsers') {
    const users = await __callHostTool__('database', 'getUsers', {});
    return {status: 'success', data: users};
  }

  if (currentState === 'processEmails') {
    const emails = await __callHostTool__('email', 'list', {});
    return {status: 'success', data: emails};
  }

  if (currentState === 'generateReport') {
    const report = await __callHostTool__('reporting', 'generate', {data});
    return {status: 'success', data: report};
  }

  return {status: 'error'};
}
```

**How it executes:**

1. **Load graph**: State machine reads workflow definition
2. **Start state**: Execute initial state code ('fetchUsers')
3. **One chunk**: Only code for current state runs
4. **Transition**: Based on onDone/onError, move to next state
5. **Save state**: Store which state we're in + results
6. **Repeat**: Resume in next state on next execution
7. **Complete**: Reach final state, workflow done

**Explicit control** - you define the states and transitions explicitly.

---

## Usage Patterns

### Quick Start: Implicit xstate (Default)

**Best for**: Most tasks, simple HTTP-based workflows

```bash
# Create new task
npx sequential-ecosystem create-task my-task

# Sync tasks to database (if configured)
npx sequential-ecosystem sync-tasks

# Execute task
npx sequential-ecosystem run my-task --input '{"userId": "123"}'
```

### Advanced: Explicit xstate Graphs

**Best for**: Complex workflows with multiple paths

```bash
# Create task with state graph
npx sequential-ecosystem create-task complex-task --with-graph

# Define states in tasks/complex-task/graph.json
# Define handlers in tasks/complex-task/code.js
# Execute - xstate handles state transitions automatically
npx sequential-ecosystem run complex-task --input '{...}'
```

---

## Storage Adaptor System

The system abstracts storage to support multiple backends transparently:

```
┌─────────────────────────────────────────────────────┐
│ tasker-sequential (task execution logic)             │
│ - Execution engine                                  │
│ - No storage knowledge                              │
└────────────────────┬────────────────────────────────┘
                     │
                     │ Uses StorageAdapter interface
                     │
         ┌───────────┴──────────────────┐
         │                              │
         v                              v
    ┌──────────────┐          ┌─────────────┐
    │ FolderAdapter│          │ tasker-     │
    │ (Flat Files) │          │ adaptor-    │
    │              │          │ sqlite      │
    │ JSON files   │          │             │
    │ (default)    │          │ SQLite DB   │
    └──────────────┘          └─────────────┘
         │                          │
         v                          v
    ┌──────────────┐          ┌──────────────┐
    │ tasks/       │          │ tasker-      │
    │ (folder)     │          │ adaptor-     │
    │ (default)    │          │ supabase     │
    │              │          │              │
    │              │          │ PostgreSQL   │
    │              │          │ (remote)     │
    └──────────────┘          └──────────────┘
```

### Default Adaptor: Folder-Based Storage (No Setup Required)

Out of the box, tasks use **folder-based storage** (no database required):

```
tasks/
├── task-1/
│   ├── code.js              # Task code (export async function)
│   ├── config.json          # {name, description, inputs}
│   ├── meta.json            # {created, updated, version}
│   └── runs/
│       ├── run-uuid-1.json  # Execution state + results
│       └── run-uuid-N.json
└── task-2/
```

**Advantages**:
- Zero database setup needed (truly default)
- Perfect for development & testing
- Git-friendly (version control tasks)
- Easy local debugging
- No external dependencies
- Portable across systems

**Enable**: This is the default - `adaptor: "default"` or `adaptor: "folder"`

### Production Adaptor: SQLite

For production without remote database:

```bash
# Auto-uses SQLite if DATABASE_URL points to .db file
export DATABASE_URL="sqlite:./workflow.db"
npx sequential-ecosystem run my-task
```

### Remote Adaptor: PostgreSQL (Supabase)

For multi-node deployments:

```bash
# Uses Supabase PostgreSQL backend
export DATABASE_URL="postgres://user:password@host:port/db"
export SUPABASE_KEY="your-api-key"
npx sequential-ecosystem run my-task
```

### Extending with Custom Adapters (Advanced)

The adapter system uses a registry pattern that allows registering custom storage backends without modifying the framework:

```javascript
import { registerAdapter, createAdapter } from 'tasker-adaptor';
import { MyCustomAdapter } from './my-adapter.js';

// Register custom adapter
registerAdapter('mongodb', (config) => new MyCustomAdapter(
  config.mongoUrl || process.env.MONGO_URL,
  config.database || 'tasks'
));

// Use it like any built-in adapter
const adapter = await createAdapter('mongodb', {
  mongoUrl: 'mongodb://localhost:27017',
  database: 'workflow'
});
```

**Built-in adapters** are automatically registered:
- `sqlite` - SQLite database
- `supabase` - PostgreSQL via Supabase

**Creating custom adapters**:
1. Implement `StorageAdapter` interface (methods: init, createTaskRun, getTaskRun, etc.)
2. Register with `registerAdapter(name, factoryFunction)`
3. Use via `createAdapter(name, config)`

This design allows production deployments to add specialized adapters (Redis, DynamoDB, etc.) without touching the core framework.

---

## Task Execution Flow

### Overview

```
CLI Input
   ↓
[1] Load Task Code + Storage Config
   ↓
[2] Create Execution Context (xstate machine)
   ↓
[3] Run Task Code in VM
   ├─→ Implicit: FetchFlow pauses on HTTP
   ├─→ Explicit: FlowState follows state graph
   ↓
[4] Save State on Suspension
   ↓
[5] Handle External Call (__callHostTool__)
   ↓
[6] Resume from Saved State
   ↓
[7] Return Results or Continue Loop
```

### Detailed Flow (Implicit xstate)

```
Task: async function searchEmails(userId) {
  const emails = await fetch('...').then(r => r.json());  // PAUSE 1
  const threads = await fetch('...').then(r => r.json()); // PAUSE 2
  return emails;
}

EXECUTION:
[Start] → [Run code] → [Hit fetch()]
         → [PAUSE] Save {line: 2, vars: {userId}}
         → [Save to storage]
         → [HTTP happens]
         → [Load state {line: 2, vars}]
         → [Resume] → [Continue to fetch()]
         → [PAUSE] Save {line: 3, vars: {userId, emails}}
         → [HTTP happens]
         → [Resume] → [Complete]
         → [Return results]
```

### Detailed Flow (Explicit xstate)

```
Graph:
  initial: 'fetchData'
  states:
    fetchData: {onDone: 'process'}
    process:  {onDone: 'complete'}
    complete: {type: 'final'}

EXECUTION:
[Start] → [Read graph]
        → [Current state = 'fetchData']
        → [Run fetchData handler - ONE CHUNK]
        → [Save {state: 'fetchData', result}]
        → [Check transition - success, go to 'process']
        → [Resume] → [Current state = 'process']
        → [Run process handler - ONE CHUNK]
        → [Save {state: 'process', result}]
        → [Check transition - success, go to 'complete']
        → [Current state = 'complete' (final)]
        → [Return final result]
```

---

## Creating Tasks

### Implicit xstate (Default - Most tasks)

```bash
npx sequential-ecosystem create-task my-emails
```

Generates:
```
tasks/my-emails/
├── code.js              # Write your async function here
├── config.json          # {name, description, inputs: [...]}
├── meta.json            # {created, updated, version}
└── runs/                # Auto-created on first run
```

**code.js template:**
```javascript
export async function myEmails(input) {
  const {userId} = input;

  // Just write normal async code with fetch
  // xstate pauses automatically on every HTTP call

  const response = await fetch(`https://gmail.com/api/user/${userId}`);
  const data = await response.json();

  // Process results
  return {
    success: true,
    emailCount: data.length
  };
}
```

**config.json template:**
```json
{
  "name": "my-emails",
  "description": "Search Gmail inbox",
  "inputs": [
    {
      "name": "userId",
      "type": "string",
      "description": "Gmail user ID"
    }
  ]
}
```

### Explicit xstate (Complex workflows)

```bash
npx sequential-ecosystem create-task complex-flow --with-graph
```

Generates:
```
tasks/complex-flow/
├── code.js              # State handlers
├── graph.json           # xstate state machine definition
├── config.json
├── meta.json
└── runs/
```

**graph.json template:**
```json
{
  "id": "complexFlow",
  "initial": "step1",
  "states": {
    "step1": {
      "description": "First execution chunk",
      "onDone": "step2",
      "onError": "errorHandler"
    },
    "step2": {
      "description": "Second execution chunk",
      "onDone": "complete"
    },
    "errorHandler": {"type": "final"},
    "complete": {"type": "final"}
  }
}
```

**code.js template:**
```javascript
// Each function handles one state
// xstate calls the matching function for current state

export async function step1(input, context) {
  // Do one chunk of work
  const data = await __callHostTool__('service', 'method', input);
  return data;
}

export async function step2(input, context) {
  // Do next chunk of work
  const processed = await __callHostTool__('service', 'another', input);
  return processed;
}

export async function errorHandler(error) {
  return {error: error.message};
}
```

---

## CLI Reference

### Create Task

```bash
# Implicit xstate (default)
npx sequential-ecosystem create-task <name>

# Explicit xstate (with state graph)
npx sequential-ecosystem create-task <name> --with-graph

# With custom input parameters
npx sequential-ecosystem create-task <name> --inputs userId,email
```

### Execute Task

```bash
# Run with input
npx sequential-ecosystem run <task-name> --input '{"userId":"123"}'

# Run and save result
npx sequential-ecosystem run <task-name> --input '...' --save

# Dry run (check syntax without executing)
npx sequential-ecosystem run <task-name> --dry-run

# Verbose output
npx sequential-ecosystem run <task-name> --input '...' --verbose
```

### Task Management

```bash
# List all tasks
npx sequential-ecosystem list

# Show task details
npx sequential-ecosystem describe <task-name>

# View execution history
npx sequential-ecosystem history <task-name>

# View single run
npx sequential-ecosystem show <task-name> <run-id>

# Delete task
npx sequential-ecosystem delete <task-name>
```

### Sync with Database

```bash
# Sync folder tasks to configured storage
npx sequential-ecosystem sync-tasks

# Sync with specific adaptor
npx sequential-ecosystem sync-tasks --adaptor sqlite

# Sync one task
npx sequential-ecosystem sync-tasks --task my-task
```

### Configuration

```bash
# Set default storage adaptor
npx sequential-ecosystem config set adaptor sqlite

# Set default input parameters
npx sequential-ecosystem config set defaults.userId john

# View current config
npx sequential-ecosystem config show
```

---

## Environment Variables

```bash
# Storage configuration (folder-based is default, no config needed)
# Optional: use SQLite for local production
DATABASE_URL="sqlite:./workflow.db"          # SQLite backend

# Optional: use PostgreSQL/Supabase for remote deployments
DATABASE_URL="postgres://..."                # PostgreSQL/Supabase

# If using Supabase
SUPABASE_URL="https://project.supabase.co"
SUPABASE_KEY="your-api-key"

# Development
DEBUG=1                                       # Verbose logging
NODE_ENV=development                         # Dev mode

# Task execution
TASK_TIMEOUT=300000                          # 5 minute timeout
TASK_MAX_RETRIES=3                           # Retry failed tasks
```

---

## Deployment Options

### Local Development (Default - Flat Files)

```bash
# No setup needed - folder-based storage works immediately
# Tasks stored in tasks/ directory
npx sequential-ecosystem run my-task --input '{...}'
```

### Testing (Flat Files)

```bash
# Still uses folder storage - no database needed
# Execution results in tasks/my-task/runs/
npx sequential-ecosystem run my-task --input '{...}'
```

### Production (Single Node - SQLite)

```bash
# Use SQLite with backup strategy
export DATABASE_URL="sqlite:./workflow.db"
npx sequential-ecosystem run my-task --input '{...}'
```

### Production (Single Node - Flat Files)

```bash
# Use folder storage with proper backups
# Great for small to medium deployments
npx sequential-ecosystem run my-task --input '{...}'
# Backup the tasks/ directory regularly
```

### Production (Distributed - PostgreSQL)

```bash
# Use PostgreSQL via environment
export DATABASE_URL="postgres://prod-host:5432/workflow"
npx sequential-ecosystem run my-task --input '{...}'
```

### Production (Distributed - Supabase)

```bash
# Use managed PostgreSQL via Supabase
export SUPABASE_URL="https://xxx.supabase.co"
export SUPABASE_KEY="your-api-key"
npx sequential-ecosystem run my-task --input '{...}'
```

---

## Monorepo Packages

### Core Execution

**sequential-fetch** (Implicit xstate - FetchFlow)
- VM that pauses on every `fetch()` call
- State saved automatically
- Zero configuration needed
- Used by: sequential-flow, tasker-sequential

**sequential-flow** (Explicit xstate support - FlowState)
- JavaScript executor with storage adapter support
- Can use explicit state graphs
- Handles pause/resume on HTTP calls
- Used by: tasker-sequential

**tasker-sequential** (Task execution engine)
- Deployment-agnostic task runner
- Uses storage adaptor for persistence
- Handles __callHostTool__ calls
- Executable via NPX CLI

### Storage Adaptors

**tasker-adaptor** (Base interface)
- Define storage contract
- All operations go through adaptor
- Easy to add new backends

**tasker-adaptor-sqlite** (Local development)
- SQLite implementation
- Default for local testing
- Single-file database
- No server needed

**tasker-adaptor-supabase** (Production)
- PostgreSQL implementation via Supabase
- Managed database service
- Built-in auth & real-time
- Multi-node safe

### Utilities

**sdk-http-wrapper** (HTTP client)
- Wraps HTTP requests for service calls
- Built-in retry logic
- Used by task execution

**tasker-wrapped-services** (Pre-wrapped SDKs)
- Google APIs (Gmail, Docs, Sheets)
- OpenAI API
- Supabase client
- Ready-to-use in tasks

---

## Architecture Decisions

### Why Two xstate Patterns?

1. **Implicit (FetchFlow)**: For 80% of use cases - just write normal code
2. **Explicit (FlowState)**: For 20% - when you need explicit state control

This lets you:
- Start simple with implicit pattern
- Graduate to explicit when needed
- Mix patterns in same task (if carefully designed)

### Why Folder-Based Default Storage?

1. **Zero setup**: Works immediately
2. **Developer friendly**: See files on disk
3. **Git-compatible**: Version control tasks
4. **Fast**: No network latency
5. **Easy debugging**: Inspect state files directly

### Why Storage Adaptor Pattern?

1. **Deployment flexibility**: Same code on different backends
2. **Testing**: Use folder storage for tests, PostgreSQL for prod
3. **Scalability**: Swap SQLite for PostgreSQL without code changes
4. **Vendor independence**: Not locked to any specific database

---

## Common Patterns

### Pattern: Retry Logic with Implicit xstate

```javascript
async function retryableTask(input) {
  let retries = 0;
  while (retries < 3) {
    try {
      // Each fetch() automatically pauses and resumes
      const response = await fetch(url);
      return await response.json();
    } catch (e) {
      retries++;
      if (retries >= 3) throw e;
      // Wait before retry - automatic state save between attempts
      await new Promise(r => setTimeout(r, 1000 * retries));
    }
  }
}
```

### Pattern: Batch Processing with Explicit xstate

```javascript
// graph.json - process in chunks
{
  "initial": "fetchBatch1",
  "states": {
    "fetchBatch1": {"onDone": "processBatch1"},
    "processBatch1": {"onDone": "fetchBatch2"},
    "fetchBatch2": {"onDone": "processBatch2"},
    "processBatch2": {"onDone": "complete"},
    "complete": {"type": "final"}
  }
}

// code.js - one chunk per state
export async function fetchBatch1(input) {
  return await __callHostTool__('db', 'getUsers', {limit: 100});
}

export async function processBatch1(batch) {
  // Process 100 users
  return batch.map(user => ({...user, processed: true}));
}
```

### Pattern: Conditional Branching with Explicit xstate

```javascript
// graph.json
{
  "initial": "checkStatus",
  "states": {
    "checkStatus": {
      "onSuccess": "processA",
      "onFail": "processB"
    },
    "processA": {"onDone": "complete"},
    "processB": {"onDone": "complete"},
    "complete": {"type": "final"}
  }
}

// code.js
export async function checkStatus(input) {
  const status = await __callHostTool__('api', 'status', {});
  return {success: status.ok};
}

export async function processA(result) {
  // Handle success path
  return {path: 'A', result};
}

export async function processB(result) {
  // Handle failure path
  return {path: 'B', result};
}
```

---

## Getting Started Checklist

- [ ] Clone repository
- [ ] Run `bun install` (or `npm install`)
- [ ] Create first task: `npx sequential-ecosystem create-task my-first-task`
- [ ] Edit `tasks/my-first-task/code.js`
- [ ] Run task: `npx sequential-ecosystem run my-first-task --input '{}'`
- [ ] View results in `tasks/my-first-task/runs/`
- [ ] (Optional) Configure storage in `.env`
- [ ] (Optional) Sync to database: `npx sequential-ecosystem sync-tasks`

---

## Troubleshooting

### Task won't run

**Check**: Is task code valid JavaScript?
```bash
npx sequential-ecosystem run my-task --dry-run --verbose
```

**Check**: Are all environment variables set?
```bash
env | grep -E "DATABASE_URL|SUPABASE"
```

### State not saving

**Check**: Is storage adaptor configured?
```bash
npx sequential-ecosystem config show
```

**Check**: Do you have write permissions on tasks folder?
```bash
ls -la tasks/
```

### HTTP calls not pausing

**Only with Implicit xstate**: Make sure using `fetch()` not custom HTTP client.

**With Explicit xstate**: Make sure using `__callHostTool__()` not direct HTTP.

---

## Key Takeaways

1. **Two xstate patterns**: Implicit (default) and Explicit (when needed)
2. **Folder storage by default**: Zero database setup, Git-friendly
3. **Pluggable storage**: Switch backends without code changes
4. **Single CLI entry point**: `npx sequential-ecosystem`
5. **Monorepo structure**: Clear separation between execution, storage, and utilities
6. **Production-ready**: No fallbacks or mocks - only real implementations

**For a new team member**: Read this file first, then create a simple task and run it. That's the fastest way to understand the system.
